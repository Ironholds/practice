#Scrape the base CRAN url (stored as r_base_url in config.R) for URLs to each package. The data we're
#looking for /should/ be available through available.packages(), but I'll be damned if I can work out
#how to get it to give me actual, non-standard fields like BugReports or URLs.
get_package_data <- function(){
  package_names <- as.data.frame(available.packages(), stringsAsFactors = FALSE)$Package
  package_urls <- paste0("http://cran.r-project.org/web/packages/", package_names, "/index.html")
  return(list(package_urls,package_names))
}

#Retrieve the content; for each package name and URL, go to the index page, scrape the data described,
#turn it into a key-value pair data.frame, associate the package name and return, before binding
#the whole thing together into one big data.frame. Then clean it a bit, of course, to remove
#things we don't care about and sanitise key names, and strip out horrible hideous things
#like newlines that totally ruin everything for everyone.
get_content <- function(package_data){
  content <- mapply(function(url, name){
    page <- html(url, user_agent(practice_ua))
    content <- html_nodes(page, "td")
    data <- html_text(content)
    results <- as.data.frame(matrix(data, nrow = length(data)/2, byrow = TRUE), stringsAsFactors = FALSE)
    names(results) <- c("field","value")
    results$package <- name
    return(results)
  }, package_data[[1]], package_data[[2]], SIMPLIFY = FALSE)
  content <- do.call("rbind",content)
  rownames(content) <- NULL
  content$field <- gsub(x = content$field, pattern = "( |:)", replacement = "")
  content <- content[!content$field %in% unwanted_fields,]
  content <- content[!grepl(x = content$field, pattern = unwanted_fields_regex),]
  content$field[grepl(x = content$field, pattern = source_regex, perl = TRUE)] <- "download_url"
  content$value <- gsub(x = content$value, pattern = '(\n|\t|\\")', replacement = "")
  write.table(content, file = file.path(getwd(),"Datasets","raw_data.tsv"), quote = TRUE, sep = "\t",
              row.names = FALSE)
  return(spread(content, key = "field", value = "value"))
}

#Takes the spread version of the data.frame now stored in raw_data.tsv and turns it into a list of values
#calculated from each field.
parse_content <- function(content){
  
  #First, naming conventions
  package_names <- content$package
  package_names[!tolower(package_names) == package_names] <- "Mixed Case"
  package_names[grepl(x = package_names, pattern = ".", fixed = TRUE)] <- "Non-Alphanumeric"
  package_names[!package_names %in% c("Mixed Case", "Non-Alphanumeric")] <- "Lower Case"
  
  #Next, author count
  authors <- content$Author
  authors <- gsub(x = authors, pattern = "(<.*?>|\\[.*?\\])", replacement = "", perl = TRUE)
  authors <- strsplit(authors, split = "( and |,)")
  authors <- unlist(lapply(authors, length))
  
  #Repos
  links <- content$BugReports
  links[is.na(links)] <- content$URL[is.na(links)]
  links[grepl(x = links, pattern = "github", fixed = TRUE)] <- "GitHub"
  links[grepl(x = links, pattern = "r-?forge", ignore.case = TRUE)] <- "RForge"
  links[grepl(x = links, pattern = "bitbucket", fixed = TRUE)] <- "BitBucket"
  links[is.na(links)] <- "None"
  links[!links %in% c("GitHub","RForge","BitBucket","None")] <- "Other"
  
  #Unit tests
  has_tests <- content$Suggests
  has_tests[grepl(x = has_tests, pattern = "RUnit")] <- "RUnit"
  has_tests[grepl(x = content$Imports, pattern = "RUnit")] <- "RUnit"
  has_tests[grepl(x = content$Depends, pattern = "RUnit")] <- "RUnit"
  has_tests[grepl(x = has_tests, pattern = "testthat")] <- "testthat"
  has_tests[grepl(x = content$Imports, pattern = "testthat")] <- "testthat"
  has_tests[grepl(x = content$Depends, pattern = "testthat")] <- "testthat"
  has_tests[!has_tests %in% c("RUnit","testthat")] <- "None/Other"
  
  #Licensing
  licenses <- content$License
  licenses[licenses == ""] <- "None"
  licenses <- unlist(lapply(strsplit(licenses, "(\\||\\[)"), function(x){return(x[[1]])}))
  licenses <- gsub(x = licenses, pattern = "(\\(|\\+).*", replacement = "", perl = TRUE)
  licenses <- gsub(x = licenses, pattern = " $", replacement = "", perl = TRUE)
  licenses[licenses == "file LICENSE"] <- "Unknown"
  
  #Orphaned
  is_orphaned <- logical(length(content$Maintainer))
  is_orphaned[content$Maintainer == "ORPHANED"] <- TRUE
  
  #Vignettes
  has_vignettes <- logical(length(content$Vignettes))
  has_vignettes[!is.na(content$Vignettes)] <- TRUE
  
  #Roxygen2
  is_roxygenised <- lapply(content$package, function(package){
    local_temp <- tempdir()
    untar(file.path(download.packages(package, destdir = local_temp)[1,2]))
    result <- grepl(x = readLines(con = file(file.path(getwd(),package,"NAMESPACE")), n = 1),
                    pattern = "Generated by roxygen2", fixed = TRUE)
    system(paste("rm -rf", file.path(getwd(),package)))
    return(result)
  })
  
  #Handle failures
  is_roxygenised <- unlist(lapply(is_roxygenised, function(x){
    ifelse(length(x) == 0, return(FALSE), return(x))
  }))
  
  #Semantic versioning
  semantically_versioned <- grepl(x = content$Version, pattern = "\\d{1,}\\.\\d{1,}\\.", perl = TRUE)
  
  #Identify year of initial creation
  year_created <- unlist(lapply(content$package, function(package){
    try({
      archive_content <- html(paste0("http://cran.r-project.org/src/contrib/Archive/", package))
    }, silent = TRUE)
    if(exists("archive_content")){
      nodes <- html_nodes(archive_content, "td")
      dates <- unlist(mapply(function(node, node_tag){
        if(is.null(node)){
          return(NULL)
        }
        date <- strptime(html_text(node), format = "%e-%b-%Y %H:%M   ", tz = "UTC")
        if(is.na(date)){
          return(NULL)
        }
        return(as.character(substr(date,0,10)))
      
      }, node = nodes, node_tag = html_attrs(nodes)))
      if(length(dates) == 0){
        return(NA)
      } else {
        return(as.character(min(as.Date(dates))))
      }
    }
    return(NA)
  }))
  year_created[is.na(year_created)] <- content$Published[is.na(year_created)]
  year_created <- lubridate::year(as.Date(year_created))
  
  #Check if it specifies an R version
  version <- grepl(x = content$Depends, pattern = "R \\(")
  results <- data.frame(package = content$package, first_published = year_created, naming_convention = package_names,
                        author_count = authors, is_orphaned = is_orphaned, public_repository = links,
                        has_tests = has_tests, is_versioned = semantically_versioned, specifies_r_version = version,
                        is_roxygenised = is_roxygenised, copyright_license = licenses, stringsAsFactors = FALSE)
  write.table(results, file = file.path(getwd(), "Datasets", "parsed_package_data.tsv"), sep = "\t", row.names = FALSE,
                                        quote = TRUE)
  return(results)
}