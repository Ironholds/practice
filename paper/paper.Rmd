---
title: Software Engineering Standards in the R Community
author:
  - name: Oliver Keyes
    affiliation: Wikimedia Foundation
    email:  ironholds@gmail.com
  - name: Jennifer Bryan
    affiliation: University of British Columbia
    email:  jenny@stat.ubc.ca
  - name: David Robinson
    affiliation: Princeton University
    email:  admiral.david@gmail.com
abstract: R flourishes because of its wide range of user-submitted packages,
  providing generalised solutions to real-world problems. Crucial to
  these packages being useful, adopted and trusted by useRs is that they
  follow reasonable software engineering expectations, from unit tests
  to user-friendly documentation.

  We performed a quantitative and qualitative analysis of CRAN-hosted
  packages, examining their use of unit tests, internal consistency and
  documentation standards, along with many other variables. We report on
  this analysis and suggest best practises for writing new R packages,
  along with proposals to improve the standards of existing, widely-used
  packages.
  

output: rticles::rjournal_article
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, cache = TRUE)
```

```{r load_data}
library(practice)
library(plyr)
library(dplyr)
library(tidyr)
library(ggplot2)

data("CRANpractices")
```

## Introduction

## Best Practices in Software Engineering

There is no single list of "best practices" for writing high quality software, but there are some general traits that such software possesses. From the perspective of the user, software should be accurate, fast-running and easy to use. From the perspective of the developer, the internal code should be maintainable, portable and lend itself to being tested.\citet{codecomplete} We can point to specific conventions or expectations that are built on these traits:

1. **Unit and integration tests**: code that tests whether code run by the user is fit for use, by performing operations and checking that the results are as expected. This touches on both "accuracy" (it prevents the wrong result being provided to the user) and "maintainability" (it gives the developer a way of conveniently checking that modifications have not broken functionality before releasing software). In R, unit tests can be created in an *ad-hoc* fashion or using a pre-existing testing framework, such as *RUnit*\citet{RUnit} or *testthat*\citet{testthat}.

## Practices in CRAN

Some figures and analyses, like Figure \ref{fig:CRAN_vignettes}.

```{r caption_calculations, dependson = "load_data"}
use_vignettes <- sum(CRANpractices$vignette_format != "None")
use_vignettes_percent <- 100 * use_vignettes / nrow(CRANpractices)
```

\begin{figure}
```{r vignette_figure, dependson = "load_data"}
vignette_count <- CRANpractices %>%
  count(vignette_format, vignette_builder) %>%
  ungroup() %>%
  gather(metric, choice, -n) %>%
  mutate(metric = revalue(metric, c(vignette_format = "Vignette Format",
                                    vignette_builder = "Vignette Builder"))) %>%
  filter(choice != "None") %>%
  mutate(choice = reorder(choice, n, function(x) -mean(x)))

ggplot(vignette_count, aes(choice, n)) +
  geom_bar(stat = "identity") +
  facet_wrap(~ metric, scale = "free", ncol = 2) +
  xlab("Choice") +
  ylab("Number of packages") +
  theme_bw(base_size = 10) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
\caption{Distribution of the choice of vignette builder and format, among the `r round(use_vignettes_percent, 1)`\% of CRAN packages that use vignettes. \label{fig:CRAN_vignettes}}
\end{figure}

\bibliography{RJreferences}
